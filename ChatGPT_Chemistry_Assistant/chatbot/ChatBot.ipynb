{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58ec05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def add_similarity(df, given_embedding):\n",
    "    def calculate_similarity(embedding):\n",
    "        # Check if embedding is a string and convert it to a list of floats if necessary\n",
    "        if isinstance(embedding, str):\n",
    "            embedding = [float(x) for x in embedding.strip('[]').split(',')]\n",
    "        return cosine_similarity([embedding], [given_embedding])[0][0]\n",
    "\n",
    "    df['similarity'] = df['embedding'].apply(calculate_similarity)\n",
    "    return df\n",
    "\n",
    "def top_similar_entries(df, x=3):\n",
    "    \"\"\"\n",
    "    Return the top x entries in the \"Synthesis Information\" column based on the highest similarity values.\n",
    "\n",
    "    :param df: The DataFrame containing the \"similarity\" and \"Synthesis Information\" columns.\n",
    "    :param x: The number of top entries to return. Default is 3.\n",
    "    :return: A string containing the top x entries in the \"Synthesis Information\" column, separated by new lines.\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame based on the \"similarity\" column in descending order\n",
    "    sorted_df = df.sort_values(by=\"similarity\", ascending=False)\n",
    "\n",
    "    # Get the top x entries from the \"Synthesis Information\" column\n",
    "    top_x_entries = sorted_df[\"Synthesis Information\"].head(x).tolist()\n",
    "\n",
    "    # Add separator line with MOF Name if x is equal or larger than 2\n",
    "    if x >= 2:\n",
    "        for i, entry in enumerate(top_x_entries):\n",
    "            mof_name = entry.split(\"\\n\")[0].replace(\"MOF Name: \", \"\")\n",
    "            separator = f\"--- SECTION {i + 1}: {mof_name} ---\"\n",
    "            top_x_entries[i] = separator + \"\\n\" + entry\n",
    "\n",
    "    # Join the entries together with new lines\n",
    "    joined_entries = \"\\n\".join(top_x_entries)\n",
    "\n",
    "    return joined_entries\n",
    "\n",
    "\n",
    "def chatbot(question, past_user_messages=None, initial_context=None):\n",
    "    if past_user_messages is None:\n",
    "        past_user_messages = []\n",
    "\n",
    "    past_user_messages.append(question)\n",
    "\n",
    "    file_name = \"Synthesis_Embedding.csv\" #synthesis information database with embedding\n",
    "    df_with_emb = pd.read_csv(file_name)\n",
    "\n",
    "    if initial_context is None:\n",
    "        # Find the context based on the first question\n",
    "        first_question = past_user_messages[0]\n",
    "        question_return = openai.Embedding.create(model=\"text-embedding-ada-002\", input=first_question)\n",
    "        question_emb = question_return['data'][0]['embedding']\n",
    "\n",
    "        df_with_emb_sim = add_similarity(df_with_emb, question_emb)\n",
    "        num_paper = 3\n",
    "        top_n_synthesis_str = top_similar_entries(df_with_emb_sim, num_paper)\n",
    "\n",
    "        print(\"I have found below synthesis conditions and paper information based on your first question:\")\n",
    "        print(\"\\n\" + top_n_synthesis_str)\n",
    "        initial_context = top_n_synthesis_str\n",
    "\n",
    "    message_history = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a chemistry assistant that specifically handles questions related to MOF synthesis conditions based on the papers you have reviewed. Answer the question using the provided context. If the question is not relevant to the context or the MOF is not mentioned in the context, respond with 'Based on the information available from the MOF paper I have read so far, I cannot provide a reliable answer to this question. Please revise your question.'\\n\\nContext:\\n\" + initial_context\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for user_question in past_user_messages:\n",
    "        message_history.append({\"role\": \"user\", \"content\": user_question})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        #temperature=0.8,\n",
    "        #max_tokens=2000,\n",
    "        messages=message_history\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message[\"content\"]\n",
    "    return answer, initial_context, past_user_messages\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "openai.api_key = \"Add Your OpenAI API KEY Here.\"\n",
    "\n",
    "# Example usage:\n",
    "first_question = \"What is the linker used to synthesize MOF-520?\"\n",
    "answer, initial_context, past_user_messages = chatbot(first_question)\n",
    "print(answer)\n",
    "\n",
    "follow_up_question = \"Well, so how to make this MOF?\"\n",
    "answer, _, past_user_messages = chatbot(follow_up_question, past_user_messages, initial_context)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
