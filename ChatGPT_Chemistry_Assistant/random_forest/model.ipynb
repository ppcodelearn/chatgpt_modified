{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (f1_score, recall_score, precision_score, \n",
    "                             roc_auc_score, balanced_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data and drop unused columns\n",
    "\n",
    "data = pd.read_csv(\"processed_data.csv\")\n",
    "t_ys = data[\"result\"].values\n",
    "Xs = data.drop([\"result\"], axis=1).fillna(0.)\n",
    "nan_mask = np.all(data == 0, axis=0)\n",
    "t_Xs = Xs.drop(list(data.columns[nan_mask]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# held-out set\n",
    "Xs, hXs, ys, hys = train_test_split(t_Xs,t_ys, train_size=0.8, random_state=49, stratify=t_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursive feature reduction\n",
    "\n",
    "clf = RandomForestClassifier(criterion=\"entropy\", random_state=49, class_weight=\"balanced\")\n",
    "rfecv = RFECV(\n",
    "    estimator=clf,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    min_features_to_select=20,\n",
    ")\n",
    "rfecv.fit(Xs.values, ys)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = np.arange(0.4, 1, 0.1)\n",
    "X_REF = Xs.values[:, rfecv.support_]\n",
    "params = {\"n_estimators\": np.arange(50, 250, 50),\n",
    "            \"min_samples_leaf\": np.arange(5, 30)}\n",
    "REF_ac = {\"train\": [], \"test\": [], \"held out\": [], \"f1\": [], \"p\": [], \"r\": [], \"auc\": []}\n",
    "prev = 0\n",
    "prev_test = 0\n",
    "\n",
    "np.random.seed(49)\n",
    "split_states = np.random.randint(100, size=10)\n",
    "\n",
    "for s in train_size:\n",
    "    train_ac = np.zeros(10)\n",
    "    test_ac = np.zeros(10)\n",
    "    held_ac = np.zeros(10)\n",
    "    test_F1 = np.zeros(20)\n",
    "    test_p = np.zeros(20)\n",
    "    test_r = np.zeros(20)\n",
    "    test_auc = np.zeros(20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_REF, ys, train_size=s, random_state=49) \n",
    "    for i, si in enumerate(split_states):\n",
    "        # hyperparameter tunning \n",
    "        rf = RandomForestClassifier(criterion=\"entropy\", random_state=49, class_weight=\"balanced\")\n",
    "        clf = RandomizedSearchCV(rf, params, n_iter=10, random_state=si)\n",
    "        search = clf.fit(X_train, y_train)\n",
    "        \n",
    "        #print(search.best_params_)\n",
    "        best_rf = clf.best_estimator_\n",
    "    \n",
    "        test_pred = best_rf.predict(X_test)\n",
    "        htest_pred = best_rf.predict(hXs.values[:, rfecv.support_])\n",
    "        train_pred = best_rf.predict(X_train)\n",
    "        test_ac[i] = balanced_accuracy_score(y_test, test_pred)\n",
    "        held_ac[i] = balanced_accuracy_score(hys, htest_pred)\n",
    "        if test_ac[-1] > prev_test:\n",
    "            prev_test = test_ac[-1]\n",
    "            best_test_model = deepcopy(best_rf)\n",
    "        if held_ac[-1] > prev:\n",
    "            prev = held_ac[-1]\n",
    "            best_model = deepcopy(best_rf)\n",
    "\n",
    "        #print(f\"seed {i}, balanced accuracy {test_ac[-1]}, accuracy {best_rf.score(X_test, y_test)}\")\n",
    "        test_F1[2*i] = f1_score(y_test, test_pred)\n",
    "        test_p[2*i] = precision_score(y_test, test_pred)\n",
    "        test_r[2*i] = recall_score(y_test, test_pred)\n",
    "        test_auc[2*i] = roc_auc_score(y_test, best_rf.predict_proba(X_test)[:, 1])\n",
    "        train_ac[i] = balanced_accuracy_score(y_train, train_pred)\n",
    "\n",
    "        test_F1[2*i+1] = f1_score(hys, htest_pred)\n",
    "        test_p[2*i+1] = precision_score(hys, htest_pred)\n",
    "        test_r[2*i+1] = recall_score(hys, htest_pred)\n",
    "        test_auc[2*i+1] = roc_auc_score(hys, best_rf.predict_proba(hXs.values[:, rfecv.support_])[:, 1])\n",
    "    \n",
    "    REF_ac[\"train\"] += [train_ac]\n",
    "    REF_ac[\"test\"] += [test_ac]\n",
    "    REF_ac[\"held out\"] += [held_ac]\n",
    "    REF_ac[\"f1\"] += [test_F1[0::2], test_F1[1::2]]\n",
    "    REF_ac[\"p\"] += [test_p[0::2], test_p[1::2]]\n",
    "    REF_ac[\"r\"] += [test_r[0::2], test_r[1::2]]\n",
    "    REF_ac[\"auc\"] += [test_auc[0::2], test_auc[1::2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem142",
   "language": "python",
   "name": "chem142"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
